fastapi==0.110.2
uvicorn[standard]==0.29.0
requests==2.31.0
llama-cpp-python==0.2.72
